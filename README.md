# Overview

In this project, I build a character-level transformer-based language model, something like GPT(Generative Pretrained Transformer). Once the model is trained, we can generate infinite text.

# Dataset

Since training on chunk of internet requires a lot of _compute_ and _time_, here I work with a [tiny shakespeare](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt) dataset.

# Usage

```
pip install -r requirements.txt
```
